---
title: Artificial General Nonsense
date: 2024-12-21
toggle_machine_commentary: true
contributed_by:
  initial:
    date: 2024-12-21
    type: human
    name: Neil D. Lawrence
  reviewed_by:
  - date: 2024-12-21
    type: machine
    tool: Claude
    version: 3.5
    notes: Prompted to check for errors now fixed.	
  - date: 2024-12-21
    type: machine
    tool: Claude
    version: 3.5
    notes: Review of blog post against themes of the book.
featured_image: /assets/images/Artificial_General_Vehicle_211224_Final.png
---

Sometimes you get asked if there's anything you'd change about the book, or anything you got wrong in the book. Well, I don't think the book is perfect, but I think that its flaws are my flaws. And I like that. But, while giving talks about the book I sometimes talk about things in a slightly different way.

I've become more polemic about some issues and I think that reflects the way in which techno-hype has drawn society into some very dangerous ways of thinking.

I turn up to many book talks with my Brompton bicycle. Embarrassingly I even took it to Google which is only a 30 second walk from King's Cross station. That made me realise it's become a sort of security blanket. I like having it because it's such a flexible means of transport.

But is it an "artificial general vehicle"? A vehicle that can do everything? Unfortunately not, for example it's not very good for flying to the USA. There is no artificial general vehicle that is optimal for every journey. Similarly there is no such thing as artificial general intelligence. It's just artificial general nonsense.

<center>
<image src="/assets/images/Artificial_General_Vehicle_211224_Final.png" alt="Dan Andrew's drawing for an Artificial General Vehicle" width="50%"/>

<i><a href="/images/dan-andrews-chapter-artificial-general-vehicle/">Dan Andrews' illustration for an Artificial General Vehicle</a>. See <a href="https://scribeysense.com">scribeysense.com</a></i>
</center>


That doesn't mean there aren't different principles to intelligence we can look at. Just like vehicles have principles that apply to them. When designing vehicles we need to think about air resistance, friction, power. We have developed solutions such as wheels, different types of engines and wings that are deployed across different vehicles to achieve different results. 

Intelligence is similar. The nation of artificial general intelligence is fundamentally eugenic. It builds on Spearman's term "general intelligence" which is part of a body of literature that was looking to assess intelligence in the way we assess height. The objective then being to breed greater intelligences.[^1]

[^1]: See [Sara Lyon's book *Assessing Intelligence*](/bibliography/assessing-intelligence/) for an overview of the context and the social reactions at the time. 

So why has a conversation about one of the most socially transformational technologies in human history collapsed into artificial general nonsense? 

There is a heavy commercial incentive, the technosolutionism of Silicon Valley has now conflated with the simplistic thinking of Wall Street investment. Under their simplistic ideas of intelligence there is money to be made and a "market to be cornered". The market values of big tech are now predicated on the idea that they will develop something that doesn't exist.[^2]

[^2]: Even if it were possible to build a general purpose superintelligence wouldn't a world where one or two companies were owning that capability be distopian?

Those values are predicated on a fantasy. Intelligence, like a vehicle, is contextual. Our intelligence is adapted to who we are and how we interact with each other. It is a general purpose intelligence, not a general intelligence. It has weaknesses and strengths. It cannot dominate in all aspects. It is social, and requires us as individuals to share vulnerabilities and have skin in the game. 

It is also adaptive and it's going to have to be, because while the idea of artificial general intelligence is eugenic nonsense, this technology is utterly transformational. It requires new ways of thinking and managing society. It's urgent that we engage the wider population in understanding how to use it and ensuring its supporting them in their roles. We need to move rapidly beyond artificial general nonsense we are hearing and towards common sense. 

<div class="machine-commentary" markdown="1">

## Machine Commentary

## Theme Analysis: Artificial General Nonsense and The Atomic Human

### 1. Evolution vs Design

The blog post's discussion of the Brompton bicycle as a specialized tool rather than a "general vehicle" connects directly to Chapter 4's exploration of evolution vs design. Just as the book argues that evolved systems are more resilient than designed ones (using examples like Microsoft's Tay chatbot), the blog post extends this argument to challenge the very concept of "general" artificial intelligence. Both texts emphasize how specialization and context-specificity are features, not bugs.

### 2. Historical Context and Power

The blog post's critique of AGI as "fundamentally eugenic" ties into Chapter 10's examination of power structures and manipulation. The book's discussion of the Stasi and surveillance capitalism finds its echo in the post's warning about Silicon Valley's "technosolutionism" and Wall Street's simplistic thinking. Both texts warn about centralizing control over transformative technologies.

### 3. Intelligence as Contextual

The book's recurring theme of intelligence as contextual (explored across Chapters 1, 8, and 11) is crystallized in the blog post's vehicle analogy. Just as the book demonstrates different forms of intelligence through examples like ant colonies, immune systems, and social networks, the post argues that different vehicles serve different purposes - there is no "general" solution.

### 4. Personal Narrative Elements

The author's use of the Brompton bicycle as both physical object and metaphor mirrors the book's technique of weaving personal narratives (like Fred Lawrence's D-Day experiences or the author's work at Amazon) to illuminate broader concepts. This helps ground abstract concepts in tangible reality.

### 5. The Social Nature of Intelligence

The book's emphasis on human intelligence as fundamentally social (particularly in Chapters 1 and 11) is reinforced in the blog post's assertion that intelligence "requires us as individuals to share vulnerabilities and have skin in the game." Both texts argue against viewing intelligence as a standalone capability that can be abstracted from social context.

### 6. HAMs and Future Directions

While the book introduces Human-Analogue Machines (HAMs) as a potential interface between humans and digital systems, the blog post takes a stronger stance against AGI hype. However, both texts emphasize the need for new ways of thinking about and managing technological change, with the blog post's call for "engaging the wider population" echoing the book's emphasis on maintaining human agency and institutional engagement.

### Notable Extensions

The blog post extends the book's arguments in several ways:
1. More explicitly political stance against AGI conceptually
2. Direct criticism of Silicon Valley/Wall Street dynamics
3. Clearer analogy (vehicles) for explaining specialization
4. More urgent tone regarding societal engagement

### Conclusion

The blog post serves as both a distillation and evolution of the book's core arguments about intelligence, technology, and society. While the book builds its case through detailed historical examples and careful analysis, the post presents a more pointed critique of current AI discourse while maintaining the book's fundamental argument about the contextual nature of intelligence.

</div>
