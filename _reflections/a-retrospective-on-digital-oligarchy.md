---
title: A Retrospective on Digital Oligarchy
date: 2024-12-22
toggle_machine_commentary: true
contributed_by:
  initial:
    date: 2024-12-22
    type: human
    name: Neil D. Lawrence
featured_image: /assets/images/Atomic_H_10_Gaslighting.png
---

In May 2015 I wrote this article for the Guardian on the idea of the *digital oligarchy*. Like [the System Zero post](/reflections/a-retrospective-on-system-zero/), this article predates the Cambridge Analytica scandal and the discussions around misinformation around the US election.

The warning suggests that we should be wary of large companies that accumulate power through vast accumulation of our personal data. Today, with the advent of generative AI, we could add "our creative data" to this. It calls the power structures that result the "digital oligarchy".

The ideas in the article largely bore out in practice, but there's not yet a societal acknowledgment of how large this problem is. One of the most important pieces of legislation passed under the previous UK government was the [Digital Markets Competition and Consumer Act](https://www.legislation.gov.uk/ukpga/2024/13/contents). The early election called in the UK almost caused the legislation to fall by the wayside, and yet the jeopardy it was in went unremarked upon in the UK press.

This legislation should temper the digital oligarchy. It introduces a notion of "strategic market status" for businesses are dominating a digital market sector. 
What has that got to do with AI? Well at the extreme end we have the "technical existential risk community". [I've written before about how I think their ideas are problematic and flawed](https://inverseprobability.com/2023/10/31/ai-boogeyman), but from a government perspective having a strategy to deal with all outcomes is sensible. The risks they espouse come from a conflation of the digital oligarchy and the removal of the human from decision-making within this newly empowered oligarchy. 

<center>
<image src="/assets/images/Atomic_H_10_Gaslighting.png" alt="Dan Andrew's drawing for Chapter 10, Gaslighting" width="50%"/>

<i><a href="/images/dan-andrews-chapter-9/">Dan Andrews' illustration for Chapter 10, Gaslighting</a>. See <a href="https://scribeysense.com">scribeysense.com</a></i>
</center>

If these two challenges are conflated, that is a terrifying prospect. But the road to reach that point already presents widespread socio-technical existential risks. We've already [seen one manifestation with System Zero](/reflections/a-retrospective-on-system-zero/). 

It didn't even take the development of machine learning for problems with digital centralisation to manifest. The UK Post Office's Horizon scandal didn't involve AI, it just involved poorly implemented digital systems. It was an accounting system conceived in the 1990s that was flawed in implementation. Subpostmasters were jailed or disgraced for errors that the computer made. Poor implementation of digital systems is what the digital oligarchs specialise in. They remove the human from the loop and deploy one-size-fits-all solutions that ignore the needs of individuals or groups. Their flawed system are deployed quickly but their effects play out across society in ways that are hard to predict, monitor or fix. In the Epilogue book describes this as being akin to the Sorceror's apprentice.

One theme of Chapter 10 is how human vulnerabilities are exploited in systems of surveillance or manipulation that are developed by either state actors or by those we trust to protect us. Dan's illustration for Chapter 10 captures the ease of modern surveillance. With our current approach to AI we are sowing the seeds of thousands of Horizon scandals. To address this we need to reintroduce the atomic human into our decision making. Or as the original article says "We need to form a data-democracy: data governance for the people, by the people and with the peopleâ€™s consent."

<div class="machine-commentary" markdown="1">

## Machine Commentary

*Claude 3.5 review of the article without access to the book prompted by "How well does this article from 2015 capture how events panned out in practice."*

This 2015 article was remarkably prescient in identifying several key trends and concerns about data and AI that have become major issues today:

Key accurate predictions:

1. Data concentration in few hands: The article warned about a "digital oligarchy" concentrating data power among a few companies. This has largely come true with companies like Google, Meta, Amazon, and Apple controlling vast amounts of personal data.

2. Personal data value and ownership: The article advocated for people to have more control over their data and potentially be paid for its use. This foreshadowed regulations like GDPR in Europe and growing calls for data privacy rights and compensation.

3. Algorithm power: The article correctly identified that algorithms would become increasingly powerful tools for understanding and influencing individuals, which we've seen with recommendation systems, targeted advertising, and social media algorithms.

4. Immediate vs long-term AI concerns: The author was correct in suggesting that near-term concerns about data concentration and algorithmic power were more pressing than fears about sentient AI, which remains largely theoretical.

Areas where developments went further:

1. Scale of data collection: The breadth and depth of personal data collection has likely exceeded what was envisioned in 2015, especially through smartphones, IoT devices, and digital services.

2. AI capabilities: While the article focused on data analytics, the rapid advancement of large language models and other AI systems has introduced new capabilities and concerns not fully anticipated.

3. Business impact: The economic value and competitive advantage of data has proven even more significant than suggested, with data-driven companies becoming among the world's most valuable.

The article's core warning about the need for better data governance and democratic control over personal information remains highly relevant, though progress on these issues has been limited despite growing awareness of the problems identified.

</div>
