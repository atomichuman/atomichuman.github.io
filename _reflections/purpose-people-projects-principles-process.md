---
title: Purpose, People, Projects, Principles, Process
date: 2024-12-26
toggle_machine_commentary: true
contributed_by:
  initial:
    date: 2024-12-26
    type: human
    name: Neil D. Lawrence
  reviewed_by:
  - date: 2024-12-26
    type: machine
    tool: Claude
    version: 3.5
    notes: Proof read of draft leading to some error fixes.
  - date: 2024-12-26
    type: machine
    tool: Claude
    version: 3.5
    notes: Prompt to provide a machine commentary.  	
featured_image: /assets/images/DALLE-2024-12-26_132949-a-makonde-style-intricate-carving-featuring-monkeys-climing-and-intertwing-on-dense-flowing-vines.webp
---

Across the twelve days of Christmas, I'm sharing stories from "who is stepping up?" to the challenges laid out in *The Atomic Human*. These are personal stories, but involve people and projects that have inspired me. 

It's hard to know how to address these challenges and context is key, some of these projects have their origins a decade ago. To remind people of context, I've provided links to three events from that period.

1. [A short manifesto](/archive/open-data-science-initiative/) on what I thought of as "open data science" from 2014.
2. [A transcript of a panel](/archive/icml-deep-learning-workshop-panel/) from the ICML 2015 Deep Learning Workshop involving Demis Hassabis, Yann LeCun, Yoshua Bengio, Kevin Murphy, me and Juergen Schmidhuber moderated by Max Welling. 
3. [An overview of conclusions from a public dialogue report](/archive/royal-society-ml-working-group-public-dialogue/) carried out in the UK by the Royal Society in January and February 2016.

It's interesting to look back and see what we got right, and what we got wrong. In the panel, most people weren't concerned about domination of academia by tech companies. Also, their advantage was seen to be more coming from data, whereas today we would think of compute as playing a very significant role. 

Looking back from a personal perspective, I think I underplayed the threat presented by digital oligarchy.[^1] Although, it's hard to remember what I thought privately. Even then I'm crediting Amazon for funding compute, and in the UK in particular government investment in machine learning was very low, corporate sponsorship was and remains an important source of funding.[^2]

[^1]: And the mechanisms by which it would come about, although the route is there in the panel. As Demis suggests in the panel, personal data isn't a good route for a small company to build a large AI. His solution is to work on games. But when it came to OpenAI (the founding of which was being discussed in emails between Musk and Altman at about the time of the panel) the route that worked for them (and they had enough money to try many routes together) was to use public data, the internet. Their advantage came from access to very large compute. So that was another thing the panel got wrong. 

[^2]: Even for public dialogue work we see e.g. [this project from the RSA in 2017](https://www.thersa.org/blog/2017/10/the-role-of-citizens-in-developing-ethical-ai) being sponsored by DeepMind.

When I look back at these meetings, I'm doing what I always do today, thinking "who are we missing?", "who isn't around the table that should be?". The Deep Learning Workshop panel is clearly missing voices from civic society who I think would have challenged much more some of the rather naive assumptions we had about how technology might play out in deployment. 

I'm grateful to the exposure the Royal Society Working Group gave me to a more diverse set of voices, and that's part of the foundation on which I continue to approach these problems. People are important. And thinking of people brings me to a mental model I use for evaluating which initiatives to get involved with. My hope is that by using a simple framework I'll avoid mistakes from the past and ensure my efforts are focused on the right areas.

To set them against the wider context, for each of the initiatives we'll look at across the twelve days of Christmas, we'll make loose use of a framework I use to contextualise the work. It's a simple mental model for institution building that I call this the five Ps model.

<center>
<image src="/assets/images/DALLE-2024-12-26_132949-a-makonde-style-intricate-carving-featuring-monkeys-climing-and-intertwing-on-dense-flowing-vines.webp" width="50%"/>

<i>DALL-E Generated version of spiritual animals engaging in the five Ps process in the style of <a href="https://en.wikipedia.org/wiki/Makonde_art">Makonde art</a>.</i>
</center>


The five Ps are: purpose, people, projects, principles, and process. 

The model is a useful sanity check (for me) that I hope lifts my thinking and it is useful in judging how to prioritise my own attention. I hope it's foundational for building initiatives that will become institutions that people will rely on to ensure the type of collaborative future that *The Atomic Human* envisages.

The first P is purpose, because that's the shared idea around which everything revolves. While I think of the people as being critical, how do you bring the right people together? People convene around purpose. 

But a purpose is often only loosely defined, so it's important to move quickly from the purpose to define projects with actionable outcomes that individual people can agree on. A lofty purpose can be realised in many different ways, but actionable projects force the group to talk about the nitty-gritty about what everyone is trying to achieve and how they're going about it. 

As projects are developed, we can start to think about principles. These capture what it is about the projects that are working and help in choosing future directions. The principles are specific to the initiative, they characterise how the initiative goes about its work. For example, in Data Science Africa they are described as the organisation's "core tenets".[^3]

[^3]: They are referenced e.g. in [pg 6 of this document](https://www.datascienceafrica.org/assets/DSA-Strategy.pdf). There are five: (i) By Africa, (ii) Student Focus, (iii) About Solutions, (iv) Sustainable and Inclusive, and (v) Agile. Each of the tenets has a longer description that the board reads to remind themselves of their priorities when they meet. 

The final P is process. Process is necessary for sustainability in an institution. In any long-lived institution it may be easier to understand the process than the purpose. That's because over time institutions evolve to have personalities that are suited to the role they find in society. Such institutions embed their learnings in their processes. But, for a young agile institution it's important to keep the balance between process and purpose right. I avoid young projects that have placed process ahead of purpose, but I know that once the role of an initiative has been understood, developing process is an important part of consolidating the initiative. 

There many aspects missing from this simple model, but it seems a useful starting point to talk about the work of colleagues that I've admired. Work that doesn't make it onto the front page of Nature or into MIT Technology Review, but work that I think is vital in ensuring the open society is preserved.

<div class="machine-commentary" markdown=1>

### Machine Commentary

*NL*: Can you provide a machine commentary for this post on how it might help address the challenges laid out in The Atomic Human?

*Claude*: Let me analyze how this post connects to the key themes and challenges from The Atomic Human:

1. Institutional Response to Digital Oligarchy:
- The post acknowledges the growing threat of digital oligarchy (which Chapter 11-12 warn about) and the need for institutional counterbalances
- It proposes a structured framework (5 Ps) for building sustainable institutions that can act as "honest brokers" in AI development, addressing concerns raised in the Epilogue
- The reflection on past oversights (like underestimating corporate influence) shows evolution in thinking about institutional responses

2. Diverse Voices and Social Context:
- The emphasis on "who isn't around the table" directly addresses the book's concern about AI development lacking diverse perspectives and social context
- The Royal Society Working Group experience demonstrates learning about importance of civic society voices, connecting to the book's emphasis on cultural context
- This aligns with the book's warning about dangers of narrow technical perspectives in AI development

3. Purpose and Human Agency:
- The framework's emphasis on purpose reflects the book's argument that human intent and agency must guide technological development
- Focus on bringing people together around shared purpose addresses the book's concern about maintaining human control over technology
- The balance between purpose and process speaks to maintaining human values while building sustainable institutions

4. Projects and Practical Solutions:
- The emphasis on actionable projects aligns with the book's call for practical solutions over theoretical frameworks
- This connects to the Epilogue's emphasis on pragmatic approaches to AI challenges
- The focus on specific outcomes helps bridge between high-level purpose and concrete action

5. Process and Cultural Evolution:
- The discussion of how institutions develop personality over time reflects the book's emphasis on cultural evolution
- The warning about overemphasizing process in young institutions shows awareness of need for adaptability
- This connects to the book's argument about importance of cultural context in intelligence

The post effectively proposes a framework for building institutions that could help address the book's concerns about maintaining human agency and cultural context in technological development while avoiding the pitfalls of digital oligarchy.


</div>
