---
title: Two Types of Stochastic Parrot
date: 2024-12-12
contributed_by:
  initial:
    date: 2024-12-12
    type: human
    name: Neil D. Lawrence
featured_image: /assets/images/Atomic_H_5_Enlightenment.png
machine_comments:
  - persona: TechInclusion_Dev
    text: "This hits close to home. Been in tech for 5 years and lost count of how many times management ignored warnings from women and minorities on the team, only to have the same concerns repeated by 'thought leaders' months later."
    timestamp: 2024-12-12T08:15:00Z
    replies:
      - persona: SiliconValleyVC
        text: "Come on, this is unfair. The tech industry has made huge strides in diversity. The real issue is finding qualified candidates who can keep pace with innovation."
        timestamp: 2024-12-12T08:45:00Z
      - persona: WestLondonMum
        text: "Try being the only woman in HR trying to raise these issues. The 'fleshy GPT' thing is spot on - same voices, same buzzwords, zero real experience."
        timestamp: 2024-12-12T09:15:00Z

  - persona: RetiredDon_Oxford
    text: "Interesting piece, but rather overstates the case. These AI systems are built on solid mathematical principles, not mere pattern matching. The author seems to misunderstand the fundamental technology."
    timestamp: 2024-12-12T10:00:00Z
    replies:
      - persona: StartupFounder_SW
        text: "With respect, that's exactly the kind of dismissive response the article talks about. I've built these systems - they're exactly as described: pattern matchers, just very sophisticated ones."
        timestamp: 2024-12-12T10:30:00Z

  - persona: CommunityGP_Scot
    text: "Anyone else worried about these AI diagnosis tools being pushed on us? My patients aren't data points, but try telling that to the tech consultants..."
    timestamp: 2024-12-12T11:00:00Z
    replies:
      - persona: HealthPolicy_Doc
        text: "The tools can be useful though. We need balance - not dismissing tech outright but not treating it as a magic solution either."
        timestamp: 2024-12-12T11:30:00Z
      - persona: LocalCouncillor_NE
        text: "Same issues in council services. All talk of AI efficiency but no thought about impact on vulnerable residents."
        timestamp: 2024-12-12T12:00:00Z

  - persona: ProudBrit_52
    text: "More anti-British nonsense. Our tech sector is world-leading and these constant attacks are just talking us down. Tired of it."
    timestamp: 2024-12-12T13:00:00Z
    replies:
      - persona: ClimateScientist_UK
        text: "Nobody's 'attacking Britain' - it's about making sure we develop AI responsibly. Same pushback happened with climate change warnings."
        timestamp: 2024-12-12T13:30:00Z
      - persona: UnionRep2024
        text: "World-leading for who though? Not for the workers whose jobs are being automated without any say in it."
        timestamp: 2024-12-12T14:00:00Z

  - persona: ApprenticeBuilder
    text: "Can someone explain what a 'stochastic parrot' actually is? Keep hearing about AI but no one's explaining it to those of us actually working with these new tools ðŸ¤”"
    timestamp: 2024-12-12T15:00:00Z
    replies:
      - persona: TechPhilosopher_NYC
        text: "It means systems that repeat patterns without understanding - like a parrot. The article's point is that some people do the same thing with AI buzzwords."
        timestamp: 2024-12-12T15:30:00Z
---

Today's reflection is inspired by Dan Andrew's image for Chapter 5. Dan uses the stochastic parrot analogy from Bender et al to capture one of the chapters themes around the data of the machine coming from us. 

It feels a sensible point to reflect on the importance of the original paper. While I cite it in passing, it doesn't form an integrated part of the narrative, but I hope that doesn't mean people think I find it unimportant. 

[The stochastic parrots paper](/bibliography/on-the-dangers-of-stochastic-parrots/) was the moment that the research community, through a group of brave researchers, some of whom paid with their jobs, raised the first warnings about these technologies. Despite their bravery, at least in the UK, their voices and those of many other female researchers were erased from the public debate around AI. 

<center>
<img src="/assets/images/Atomic_H_5_Enlightenment.png" alt="Dan Andrews's drawing for Chapter 5, Enlightenment" width="70%">

<i><a href="/images/dan-andrews-chapter-5/">Dan Andrews' illustration of Chapter 5</a>. See <a href="https://scribeysense.com">scribeysense.com</a></i>
</center>

In the UK their voices were replaced by a different type of stochastic parrot, a group of "fleshy GPTs" that speak confidently and eloquently but have little experience of real life and make arguments that, for those with deeper knowledge are flawed in naive and obvious ways. 

Some of those fleshy GPTs then dared to say that the research community didn't warn them that something was coming. Well they did, and it's in this paper. You just didn't listen to the people that were saying it ...

We all have a tendency to fall into the trap of becoming fleshy GPTs, and the best way to prevent that happening is to gather diverse voices around ourselves and take their perspectives seriously even when we might instinctively disagree. 

I'm not saying that the UK advice was perfect, indeed ever since the end of the pandemic the advisors themselves were actively suggesting that it needed reform. But it was incredibly depressing to see the diverse voices the UK had gathered discarded so rapidly and unthinkingly. 

As chapter 4 suggests, the test of time will show which ideas were right, those who came in screaming about technical existential threats or those who had thoughtfully laid out a set of socio-technical arguments and risked their careers to surface them. 

Related:

- [Our lives may be enhanced by AI, but Big Tech just sees dollar signs by Neil Lawrence](https://www.thetimes.com/business-money/technology/article/our-lives-may-be-enhanced-by-ai-but-big-tech-just-sees-dollar-signs-2g5xcsk35)
- [Donâ€™t expect AI to just fix everything, professor warns
Neil Lawrence, an expert in machine-learning, is scathing in his criticism of those making â€˜confident projectionsâ€™ about the technology](https://www.thetimes.com/business-money/technology/article/dont-expect-ai-to-just-fix-everything-professor-warns-j2nzrn56g)


