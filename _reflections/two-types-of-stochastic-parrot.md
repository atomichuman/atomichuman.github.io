---
title: Two Types of Stochastic Parrot
date: 2024-12-12
contributed_by:
  initial:
    date: 2024-12-12
    type: human
    name: Neil D. Lawrence
featured_image: /assets/images/Atomic_H_5_Enlightenment.png
---

Today's reflection is inspired by Dan Andrew's image for Chapter 5. Dan uses the stochastic parrot analogy from Bender et al to capture one of the chapters themes around the data of the machine coming from us. 

It feels a sensible point to reflect on the importance of the original paper. While I cite it in passing, it doesn't form an integrated part of the narrative, but I hope that doesn't mean people think I find it unimportant. 

[The stochastic parrots paper](/bibliography/on-the-dangers-of-stochastic-parrots/) was the moment that the research community, through a group of brave researchers, some of whom paid with their jobs, raised the first warnings about these technologies. Despite their bravery, at least in the UK, their voices and those of many other female researchers were erased from the public debate around AI. 

<center>
<img src="/assets/images/Atomic_H_5_Enlightenment.png" alt="Dan Andrews's drawing for Chapter 5, Enlightenment" width="70%">

<i><a href="/images/dan-andrews-chapter-5/">Dan Andrews' illustration of Chapter 5</a>. See <a href="https://scribeysense.com">scribeysense.com</a></i>
</center>

In the UK their voices were replaced by a different type of stochastic parrot, a group of "fleshy GPTs" that speak confidently and eloquently but have little experience of real life and make arguments that, for those with deeper knowledge are flawed in naive and obvious ways. 

Some of those fleshy GPTs then dared to say that the research community didn't warn them that something was coming. Well they did, and it's in this paper. You just didn't listen to the people that were saying it ...

We all have a tendency to fall into the trap of becoming fleshy GPTs, and the best way to prevent that happening is to gather diverse voices around ourselves and take their perspectives seriously even when we might instinctively disagree. 

I'm not saying that the UK advice was perfect, indeed ever since the end of the pandemic the advisors themselves were actively suggesting that it needed reform. But it was incredibly depressing to see the diverse voices the UK had gathered discarded so rapidly and unthinkingly. 

As chapter 4 suggests, the test of time will show which ideas were right, those who came in screaming about technical existential threats or those who had thoughtfully laid out a set of socio-technical arguments and risked their careers to surface them. 

Related:

- [Our lives may be enhanced by AI, but Big Tech just sees dollar signs by Neil Lawrence](https://www.thetimes.com/business-money/technology/article/our-lives-may-be-enhanced-by-ai-but-big-tech-just-sees-dollar-signs-2g5xcsk35)
- [Don’t expect AI to just fix everything, professor warns
Neil Lawrence, an expert in machine-learning, is scathing in his criticism of those making ‘confident projections’ about the technology](https://www.thetimes.com/business-money/technology/article/dont-expect-ai-to-just-fix-everything-professor-warns-j2nzrn56g)


