---
title: Playing in People's Backyards
date: 2024-12-24
toggle_machine_commentary: true
contributed_by:
  initial:
    date: 2024-12-24
    type: human
    name: Neil D. Lawrence
featured_image: /assets/images/Atomic_H_11_Human_Analogue.png
---

The Berkeley statistician [John Tukey](https://www.theguardian.com/news/2000/aug/16/guardianobituaries1) is said to have told a colleague "The best thing about being a statistician is that you get to play in everyone's backyard". The same is true for machine learning, data science and AI. 

Most of this play is welcomed, but there's a challenge where what starts out as play becomes a problem, the AI play ignores those who are living in the house, are experts in the domain, and a garden play-shelter becomes a concrete carbuncle ... or the owners own thoughts are drowned out by the noise the players make inviting in the press to show them their new game.

Respectful play involves understanding the home-owners and what they'd find useful. It involves first asking "how can we help".

With this approach in mind we approached my colleague [Dr Jonathan Tenney](https://www.arch.cam.ac.uk/staff/dr-jonathan-tenney), an Assyriologist in the University's department of Archeology. Instead of imposing Neural Networks on him [we followed approaches from the social sciences](https://science.ai.cam.ac.uk/2024/12/19/how-can-we-develop-machine-learning-tools-to-map-ancient-social-networks) such as grounded theory to understand Jonathan's work. 

The beauty of this approach is that we learn both ways, we better understand Jon's work and we better understand the limitations of our own systems. Part of Jon's work made it into the book, and today we end the traditional 24 days of the advent calendar by picking up on that work.

<center>
<image src="/assets/images/Atomic_H_11_Human_Analogue.png" alt="Dan Andrew's drawing for Chapter 11, Human Analogue Machines" width="50%"/>

<i><a href="/images/dan-andrews-chapter-11/">Dan Andrews' illustration for Chapter 11, Human Analogue Machines</a>. See <a href="https://scribeysense.com">scribeysense.com</a>.</i>
</center>

Part of the chapter: *Human Analogue Machines* is focussed on the extraordinary opportunities we gain when we can interface directly with computers through natural language. Jon's work looks back to the development of writing. We watched and recorded Jon as [he translated a tablet from the ancient city of Ur](https://cdli.mpiwg-berlin.mpg.de/artifacts/346976). It was a legal decision held under the Code of Hammurabi, one of the oldest legal codes dating from 1700BC. 

In the judgment witness statements contradicted themselves, and in this case the Hammurabi's code suggests trial by ordeal: the accused is thrown into the river to allow the gods to decide.

Although this was over 3000 years ago, we see the same tendency in modern AI systems. When things get complicated, let's get the AI to decide. 

This is playing in the garden of others in the worst possible manner. Undermining the original owner's confidence to such a degree that they no longer trust their own judgment and prefer the modern equivalent of trial-by-ordeal rather than expressing their professional judgment. 


<div class="machine-commentary" markdown="1">

## Commentary by Machine

</div>
