---
layout: paper
title: "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?"
author:
  - given: Emily M.
    family: Bender
  - given: Timnit
    family: Gebru
  - given: Angelina
    family: McMillan-Major
  - given: Shmargaret
    family: Shmitchell
year: 2021
isbn: 9781450383097
publisher: Association for Computing Machinery
address: New York, NY, USA
url: https://doi.org/10.1145/3442188.3445922
doi: 10.1145/3442188.3445922
abstract: >
  The past 3 years of work in NLP have been characterized by the
  development and deployment of ever larger language models, especially
  for English. BERT, its variants, GPT-2/3, and others, most recently
  Switch-C, have pushed the boundaries of the possible both through
  architectural innovations and through sheer size. Using these
  pretrained models and the methodology of fine-tuning them for specific
  tasks, researchers have extended the state of the art on a wide array
  of tasks as measured by leaderboards on specific benchmarks for
  English. In this paper, we take a step back and ask: How big is too
  big? What are the possible risks associated with this technology and
  what paths are available for mitigating those risks? We provide
  recommendations including weighing the environmental and financial
  costs first, investing resources into curating and carefully
  documenting datasets rather than ingesting everything on the web,
  carrying out pre-development exercises evaluating how the planned
  approach fits into research and development goals and supports
  stakeholder values, and encouraging research directions beyond ever
  larger language models.
booktitle: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency
pages: 610â€“623
numpages: 14
location: Virtual Event, Canada
series: FAccT '21
contributed_by:
  initial:
    type: machine
    tool: ChatGPT
    version: 4o1
    date: 2024-12-12
  reviewed_by:
    - type: human
      person_id: Neil D. Lawrence
      date: 2024-12-12
      notes: Verified inclusion of BibTeX fields into YAML format.
---
