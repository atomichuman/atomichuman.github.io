---
layout: chapter
number: 11
title: Human–Analogue Machines
contributed_by:
  initial:
    type: "machine"
    tool: "ChatGPT"
    version: 4o1
    date: "2024-12-01"
  reviewed_by:
  - type: "human"
    person_id: Neil D. Lawrence
    date: 2024-12-02
    notes: Moving computer allocated categories to separate technology and media and to merge reflections.
themes:
  - Affordances
  - Generative AI and the Sorcerer's Apprentice
  - Power Asymmetries
  - Digital Oligarchy
  - Wicked Problems
  - The Limitations of Analogy
  - Rethinking Human-Machine Interaction
  - Risks in Human-Analogue AI
historical_events:
  - Cambridge Analytica
technology:
  - Turing Universal Machine
  - Apollo Guidance Computer
people:
  - Frank Rosenblatt
  - Jonathan Tenney
reflections:
  - Playing in People's Backyards
---

<div class="machine-commentary" markdown="1">
  
### Machine Summary

Chapter 11, *Human–Analogue Machines (HAMs)*, explores the concept of machines designed to emulate human cognitive and emotional patterns. It begins by examining historical instances where machines were anthropomorphized to help humans comprehend their function, such as Donald MacKay's analogue computers and the MONIAC economic simulator. These systems aimed to model the real world through physical analogies like water flows or electrical circuits.

The chapter then transitions to modern neural networks and large language models, which mimic human thought and language patterns by learning from vast datasets. Examples include ChatGPT, which utilizes these models to interact seamlessly with humans. While these systems create opportunities for deeper engagement and understanding, they also introduce human-like flaws, including susceptibility to manipulation and bias.

Trust and vulnerability emerge as central themes. The chapter critiques the asymmetry in trust within human-machine interactions. Unlike human relationships, where trust involves mutual risk, interactions with HAMs often place humans in a position of greater vulnerability. This imbalance is compounded by machines' vast information-processing capabilities, which can lead to unforeseen outcomes and ethical dilemmas.

Finally, the chapter reflects on the lessons from aviation and space exploration, such as the Apollo program, where engineers carefully curated interfaces to maintain control over complex systems. It argues for similar approaches in human-analogue machines, emphasizing the need for responsible design to mitigate risks while maximizing societal benefits.
</div>
